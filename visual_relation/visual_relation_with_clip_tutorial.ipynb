{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Relationship Detection\n",
    "\n",
    "In this tutorial, we focus on the task of classifying visual relationships between objects in an image. For any given image, there might be many such relationships, defined formally as a `subject <predictate> object` (e.g. `person <riding> bike`). As an example, in the relationship `man riding bicycle`), \"man\" and \"bicycle\" are the subject and object, respectively, and \"riding\" is the relationship predicate.\n",
    "\n",
    "![Visual Relationships](https://cs.stanford.edu/people/ranjaykrishna/vrd/dataset.png)\n",
    "\n",
    "In the examples of the relationships shown above, the red box represents the _subject_ while the green box represents the _object_. The _predicate_ (e.g. kick) denotes what relationship connects the subject and the object.\n",
    "\n",
    "For the purpose of this tutorial, we operate over the [Visual Relationship Detection (VRD) dataset](https://cs.stanford.edu/people/ranjaykrishna/vrd/) and focus on action relationships. We define our classification task as **identifying which of three relationships holds between the objects represented by a pair of bounding boxes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"visual_relation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Dataset\n",
    "We load the VRD dataset and filter images with at least one action predicate in it, since these are more difficult to classify than geometric relationships like `above` or `next to`. We load the train, valid, and test sets as Pandas `DataFrame` objects with the following fields:\n",
    "- `label`: The relationship between the objects. 0: `RIDE`, 1: `CARRY`, 2: `OTHER` action predicates\n",
    "- `object_bbox`: coordinates of the bounding box for the object `[ymin, ymax, xmin, xmax]`\n",
    "- `object_category`: category of the object\n",
    "- `source_img`: filename for the corresponding image the relationship is in\n",
    "- `subject_bbox`: coordinates of the bounding box for the object `[ymin, ymax, xmin, xmax]`\n",
    "- `subject_category`: category of the subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running this notebook for the first time, it will take ~15 mins to download all the required sample data.\n",
    "\n",
    "The sampled version of the dataset **uses the same 26 data points across the train, dev, and test sets.\n",
    "This setting is meant to demonstrate quickly how Snorkel works with this task, not to demonstrate performance.**\n",
    "\n",
    "The full version of the dataset **uses the same 635 samples for train, 216 samples for dev, and 194 samples for test sets and is still relatively small.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Relationships:  635\n",
      "Dev Relationships:  216\n",
      "Test Relationships:  194\n"
     ]
    }
   ],
   "source": [
    "from utils import load_vrd_data\n",
    "\n",
    "# setting sample=False will take ~30 minutes to run (downloads full VRD dataset). make sure the data folder is empty before running\n",
    "sample = False\n",
    "is_test = os.environ.get(\"TRAVIS\") == \"true\" or os.environ.get(\"IS_TEST\") == \"true\"\n",
    "df_train, df_valid, df_test = load_vrd_data(sample, is_test)\n",
    "\n",
    "print(\"Train Relationships: \", len(df_train))\n",
    "print(\"Dev Relationships: \", len(df_valid))\n",
    "print(\"Test Relationships: \", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the training `DataFrame` will have a labels field with all -1s. This denotes the lack of labels for that particular dataset. In this tutorial, we will assign probabilistic labels to the training set by writing labeling functions over attributes of the subject and objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Writing Labeling Functions\n",
    "We now write labeling functions to detect what relationship exists between pairs of bounding boxes. To do so, we can encode various intuitions into the labeling functions:\n",
    "\n",
    "Here, we use [CLIP](https://arxiv.org/abs/2103.00020) model to provide context about the action happening in the image. We first crop the the bounding boxes of the object and subject from the image. We then copy them into a blank image to help the CLIP backbone focus only on the desired pair of subject and object. The similarity between text embedings of actions and embedding of the image provides a good proxy to label the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some Constants\n",
    "\n",
    "RIDE = 0\n",
    "CARRY = 1\n",
    "OTHER = 2\n",
    "ABSTAIN = -1\n",
    "\n",
    "YMIN = 0\n",
    "YMAX = 1\n",
    "XMIN = 2\n",
    "XMAX = 3\n",
    "\n",
    "DIR = \"data/VRD/sg_dataset/samples\" if sample else \"data/VRD/sg_dataset/sg_train_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use CLIP to provide context about the action happening in the image. We first crop the the bounding boxes of the object and subject from the image. We then copy them into a blank image to help the CLIP backbone focus only on the desired pair of subject and object. The similarity between text embedings of actions and embedding of the image provides a good proxy to label the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "from model import CLIPInference\n",
    "import pandas as pd\n",
    "from typing import List, Union\n",
    "\n",
    "clip_model = CLIPInference()\n",
    "\n",
    "def process_sample(x: pd.Series, actions: List[str], labels: List[int]) -> int:\n",
    "    \"\"\"Process a sample to determine its label based on visual and textual features.\"\"\"\n",
    "    if x.object_category != \"person\" and x.subject_category != \"person\":\n",
    "        return OTHER\n",
    "\n",
    "    # Extract and prepare bounding box coordinates\n",
    "    object_corners = (x.object_bbox[XMIN], x.object_bbox[YMIN], x.object_bbox[XMAX], x.object_bbox[YMAX])\n",
    "    subject_corners = (x.subject_bbox[XMIN], x.subject_bbox[YMIN], x.subject_bbox[XMAX], x.subject_bbox[YMAX])\n",
    "\n",
    "    # Embedding text and preparing the image for model inference\n",
    "    text_features = clip_model.embed_text(actions)\n",
    "    processed_image = clip_model.prepare_image(f\"{DIR}/{x.source_img}\", object_corners, subject_corners)\n",
    "    text_probs = clip_model.compute_similarity(processed_image, text_features)\n",
    "\n",
    "    return clip_model.probs_to_label(text_probs, labels)\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def lf_clip_carry(x: pd.Series) -> int:\n",
    "    \"\"\"Labeling function for determining if a person is carrying an object.\"\"\"\n",
    "    actions = [\"The person is carrying a small object in their hand\", \"The person is sitting\", \"The person is sleeping\"]\n",
    "    labels = [CARRY, OTHER, OTHER]\n",
    "    return process_sample(x, actions, labels)\n",
    "\n",
    "@labeling_function()\n",
    "def lf_clip_ride(x: pd.Series) -> int:\n",
    "    \"\"\"Labeling function for determining if a person is riding an object.\"\"\"\n",
    "    object_category = x.object_category if x.object_category != \"person\" else x.subject_category\n",
    "    riding_objects = [\"car\", \"train\", \"motorcycle\", \"bike\", \"boat\", \"van\", \"plane\", \"airplane\", \"skateboard\", \"horse\", \"skis\", \"surfboard\", \"snowboard\"]\n",
    "    if object_category not in riding_objects:\n",
    "        return ABSTAIN\n",
    "    actions = [f\"A person {verb} a {object_category}\" for verb in [\"driving a vehicle\", \"sitting inside\", \"riding on\", \"steering\", \"flying\", \"walking\", \"pushing\"]]\n",
    "    labels = [RIDE if verb != \"walking\" else OTHER for verb in actions[:-2]] + [OTHER, CARRY, OTHER]\n",
    "    return process_sample(x, actions, labels)\n",
    "\n",
    "@labeling_function()\n",
    "def lf_clip_wearing(x: pd.Series) -> int:\n",
    "    \"\"\"Labeling function for determining if a person is wearing an object.\"\"\"\n",
    "    object_category = x.object_category if x.object_category != \"person\" else x.subject_category\n",
    "    wearing_objects = [\"shirt\", \"glasses\", \"hat\", \"pants\", \"jacket\", \"shoe\", \"shoes\", \"helmet\", \"coat\", \"shorts\", \"jeans\", \"sunglasses\", \"tie\", \"watch\"]\n",
    "    if object_category not in wearing_objects:\n",
    "        return ABSTAIN\n",
    "    actions = [f\"A person is {verb} the {object_category}\" for verb in [\"wearing\", \"carrying\", \"throwing\"]]\n",
    "    labels = [OTHER, CARRY, OTHER]\n",
    "    return process_sample(x, actions, labels)\n",
    "\n",
    "@labeling_function()\n",
    "def lf_clip_sitting(x: pd.Series) -> int:\n",
    "    \"\"\"Labeling function for determining if a person is sitting on an object.\"\"\"\n",
    "    object_category = x.object_category if x.object_category != \"person\" else x.subject_category\n",
    "    sitting_on_objects = [\"chair\", \"bench\", \"sofa\", \"train\", \"tree\"]\n",
    "    if object_category not in sitting_on_objects:\n",
    "        return ABSTAIN\n",
    "    actions = [f\"A person sitting on a {object_category}\", f\"A person carrying a {object_category}\", f\"A person pointing at a {object_category}\"]\n",
    "    labels = [OTHER, CARRY, OTHER]\n",
    "    return process_sample(x, actions, labels)\n",
    "\n",
    "@labeling_function()\n",
    "def lf_clip_riding_bike(x: pd.Series) -> int:\n",
    "    \"\"\"Labeling function for determining if a person is riding a bike or motorcycle.\"\"\"\n",
    "    object_category = x.object_category if x.object_category != \"person\" else x.subject_category\n",
    "    riding_objects = [\"bike\", \"motorcycle\"]\n",
    "    if object_category not in riding_objects:\n",
    "        return ABSTAIN\n",
    "    actions = [f\"A person riding the {object_category}\", f\"The {object_category} is parked\"]\n",
    "    labels = [RIDE, OTHER]\n",
    "    return process_sample(x, actions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labeling functions have varying empirical accuracies and coverages. Due to class imbalance in our chosen relationships, labeling functions that label the `OTHER` class have higher coverage than labeling functions for `RIDE` or `CARRY`. This reflects the distribution of classes in the dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 635/635 [02:42<00:00,  3.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216/216 [00:57<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_clip_carry,\n",
    "    lf_clip_ride,\n",
    "    lf_clip_wearing,\n",
    "    lf_clip_sitting,\n",
    "    lf_clip_riding_bike,\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "L_valid = applier.apply(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_clip_carry</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>117</td>\n",
       "      <td>99</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_ride</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>0.245370</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>0.452830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_wearing</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_sitting</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_riding_bike</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j   Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "lf_clip_carry        0     [1, 2]  1.000000  0.458333   0.291667      117   \n",
       "lf_clip_ride         1  [0, 1, 2]  0.245370  0.245370   0.203704       24   \n",
       "lf_clip_wearing      2     [1, 2]  0.009259  0.009259   0.004630        1   \n",
       "lf_clip_sitting      3     [1, 2]  0.143519  0.143519   0.023148       28   \n",
       "lf_clip_riding_bike  4     [0, 2]  0.125000  0.125000   0.125000       18   \n",
       "\n",
       "                     Incorrect  Emp. Acc.  \n",
       "lf_clip_carry               99   0.541667  \n",
       "lf_clip_ride                29   0.452830  \n",
       "lf_clip_wearing              1   0.500000  \n",
       "lf_clip_sitting              3   0.903226  \n",
       "lf_clip_riding_bike          9   0.666667  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "Y_valid = df_valid.label.values\n",
    "LFAnalysis(L_valid, lfs).lf_summary(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_clip_carry</th>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.995276</td>\n",
       "      <td>0.437795</td>\n",
       "      <td>0.269291</td>\n",
       "      <td>376</td>\n",
       "      <td>256</td>\n",
       "      <td>0.594937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_ride</th>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>0.220472</td>\n",
       "      <td>0.220472</td>\n",
       "      <td>0.207874</td>\n",
       "      <td>76</td>\n",
       "      <td>64</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_wearing</th>\n",
       "      <td>2</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_sitting</th>\n",
       "      <td>3</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>0.159055</td>\n",
       "      <td>0.159055</td>\n",
       "      <td>0.018898</td>\n",
       "      <td>93</td>\n",
       "      <td>8</td>\n",
       "      <td>0.920792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_clip_riding_bike</th>\n",
       "      <td>4</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>0.137008</td>\n",
       "      <td>0.137008</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>0.505747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     j   Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "lf_clip_carry        0     [1, 2]  0.995276  0.437795   0.269291      376   \n",
       "lf_clip_ride         1  [0, 1, 2]  0.220472  0.220472   0.207874       76   \n",
       "lf_clip_wearing      2     [1, 2]  0.020472  0.020472   0.006299        9   \n",
       "lf_clip_sitting      3     [1, 2]  0.159055  0.159055   0.018898       93   \n",
       "lf_clip_riding_bike  4     [0, 2]  0.137008  0.137008   0.133858       44   \n",
       "\n",
       "                     Incorrect  Emp. Acc.  \n",
       "lf_clip_carry              256   0.594937  \n",
       "lf_clip_ride                64   0.542857  \n",
       "lf_clip_wearing              4   0.692308  \n",
       "lf_clip_sitting              8   0.920792  \n",
       "lf_clip_riding_bike         43   0.505747  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = df_train.label.values\n",
    "LFAnalysis(L_train, lfs).lf_summary(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Label Model\n",
    "We now train a multi-class `LabelModel` to assign training labels to the unalabeled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1466.46epoch/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=3, verbose=True)\n",
    "label_model.fit(L_train, seed=123, lr=0.01, log_freq=10, n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) Micro average for the multiclass setting, which calculates metrics globally across classes, by counting the total true positives, false negatives and false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1_micro': 0.6018518518518519}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model.score(L_valid, Y_valid, metrics=[\"f1_micro\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Classifier\n",
    "You can then use these training labels to train any standard discriminative model, such as [an off-the-shelf ResNet](https://github.com/KaimingHe/deep-residual-networks), which should learn to generalize beyond the LF's we've developed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataLoaders for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification import DictDataLoader\n",
    "from model import SceneGraphDataset, create_model\n",
    "\n",
    "df_train[\"labels\"] = label_model.predict(L_train)\n",
    "\n",
    "# Remove rows where the predicted 'labels' value is ABSTAIN\n",
    "df_train = df_train[df_train['labels'] != ABSTAIN]\n",
    "\n",
    "if sample:\n",
    "    TRAIN_DIR = \"data/VRD/sg_dataset/samples\"\n",
    "else:\n",
    "    TRAIN_DIR = \"data/VRD/sg_dataset/sg_train_images\"\n",
    "\n",
    "dl_train = DictDataLoader(\n",
    "    SceneGraphDataset(\"train_dataset\", \"train\", TRAIN_DIR, df_train),\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "dl_valid = DictDataLoader(\n",
    "    SceneGraphDataset(\"valid_dataset\", \"valid\", TRAIN_DIR, df_valid),\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# initialize pretrained feature extractor\n",
    "cnn = models.resnet18(pretrained=True)\n",
    "model = create_model(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "md-exclude-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|████████████████████████████████████████████████████| 40/40 [00:20<00:00,  1.92it/s, model/all/train/loss=0.915, model/all/train/lr=0.001]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.classification import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    seed = 123,\n",
    "    n_epochs=1,  # increase for improved performance\n",
    "    lr=1e-3,\n",
    "    checkpointing=False,\n",
    ")\n",
    "trainer.fit(model, [dl_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visual_relation_task/valid_dataset/valid/f1_micro': 0.6898148148148148}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score([dl_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "We have successfully trained a visual relationship detection model! The addition of a model-based LF helped improve the accuracy of labling and consequently the accuracy of the trained model improved.\n",
    "\n",
    "We recently leveraged image-based and model-based LFs to [accelerate product tagging for Wayfair](https://snorkel.ai/how-wayfair-accelerated-product-tagging-automation-with-snorkel-flow/) using Snorkel Flow platform. You can read more on how Wayfair is using our technology in [this blog post](https://www.aboutwayfair.com/careers/tech-blog/accelerating-catalog-tagging-automation-with-snorkels-data-centric-ai-platform-wayfairs-success-story)!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
